{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % TODO: State all conditions and experiment setup - how many randomly generated victims?\n",
    "# % Initialise an large area with multiple hotspots\n",
    "# % Sum all the probabilities of generating victims in said hotspots\n",
    "# % Generate hotspots\n",
    "\n",
    "# % Cluster, task and search \n",
    "# % Run 100 trials and compare \n",
    "#     % Minimum time capture\n",
    "#     % Speed of capture (average time steps),\n",
    "#     % First and last capture\n",
    "#     % Path coverage\n",
    "\n",
    "import numpy as np\n",
    "import folium\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "boundary_pts = [\n",
    "    (1.34554, 103.95949),\n",
    "    (1.34552, 103.96812),\n",
    "    (1.33954, 103.96831),\n",
    "    (1.33964, 103.95952),\n",
    "]\n",
    "\n",
    "n_hotspots = 10\n",
    "hotspots = [\n",
    "    (1.3408531, 103.9611108),\n",
    "    (1.3409068, 103.9621181),\n",
    "    (1.3402594, 103.9621944),\n",
    "    (1.3447965, 103.9637608),\n",
    "    (1.3418683, 103.9650483),\n",
    "    (1.3411711, 103.9653916),\n",
    "    (1.3443996, 103.9603276),\n",
    "    (1.3443996, 103.9648981),\n",
    "    (1.3433592, 103.9626021),\n",
    "    (1.3450968, 103.9611108)\n",
    "]\n",
    "\n",
    "hotspots_np = np.array(hotspots)\n",
    "\n",
    "\n",
    "##### Generate victims around hotspots using Gaussian distribution #####\n",
    "n_victims = 15\n",
    "victims = []\n",
    "\n",
    "# Get grid and pdf for each coordinate\n",
    "grid_x, grid_y = np.mgrid[1.33964:1.34552:100j, 103.95949:103.96831:100j]\n",
    "pos = np.dstack((grid_x, grid_y))\n",
    "combined_pdf = np.zeros(pos.shape[:2])\n",
    "covariance_matrix = [[0.00000001, 0], [0, 0.00000001]]\n",
    "\n",
    "for hotspot in hotspots:\n",
    "    rv = multivariate_normal(hotspot, covariance_matrix)\n",
    "    combined_pdf += rv.pdf(pos)\n",
    "\n",
    "# Normalize the combined PDF to avoid NaNs\n",
    "combined_pdf /= np.sum(combined_pdf)\n",
    "\n",
    "boundary_pts_np = np.array(boundary_pts)\n",
    "\n",
    "# combined_pdf.shape # is the probability associated with (100, 100) \n",
    "victim_indices = np.random.choice(np.arange(combined_pdf.size), p=combined_pdf.ravel(), size=n_victims)\n",
    "victim_coords = np.column_stack(np.unravel_index(victim_indices, combined_pdf.shape))\n",
    "victims = np.column_stack((grid_x[victim_coords[:, 0], victim_coords[:, 1]], grid_y[victim_coords[:, 0], victim_coords[:, 1]]))\n",
    "\n",
    "\n",
    "##### VISUALISATION: Plot the map with victims and hotspots #####\n",
    "map_center = [np.mean(boundary_pts_np[:, 0]), np.mean(boundary_pts_np[:, 1])]\n",
    "m = folium.Map(location=map_center, zoom_start=15)\n",
    "\n",
    "# Add boundary points to the map\n",
    "# for lat, lon in boundary_pts:\n",
    "#     folium.Marker(location=[lat, lon], popup='Boundary Point', icon=folium.Icon(color='blue')).add_to(m)\n",
    "\n",
    "boundary_pts_polyline = boundary_pts \n",
    "boundary_pts_polyline.append(boundary_pts[0])\n",
    "line=folium.PolyLine(locations=boundary_pts_polyline,weight=3,color=\"#FF0000\").add_to(m)\n",
    "\n",
    "# Victim\n",
    "for lat, lon in victims:\n",
    "    folium.Marker(location=[lat, lon], popup='Victim', icon=folium.Icon(color='green')).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_clustering import run_clustering\n",
    "\n",
    "def clustering_step(hotspots, threshold):\n",
    "    clusters = run_clustering(hotspots, threshold=threshold)\n",
    "    clusters = list(clusters.values())\n",
    "    clusters = sorted(clusters, key=lambda x:len(x[1]), reverse=False)\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        if len(clusters[i][1]) == 1:\n",
    "            cluster_coord = clusters[i][0]\n",
    "            folium.Marker(location=[cluster_coord[0], cluster_coord[1]], popup=f'Cluster{i}+Point', icon=folium.Icon(color='black')).add_to(m)\n",
    "        else:\n",
    "            cluster_coord = clusters[i][0]\n",
    "            folium.Marker(location=[cluster_coord[0], cluster_coord[1]], popup=f'Cluster{i}', icon=folium.Icon(color='black')).add_to(m)\n",
    "            for j in range(len(clusters[i][1])):\n",
    "                hotspot_coord = clusters[i][1][j]\n",
    "                folium.Marker(location=[hotspot_coord[0], hotspot_coord[1]], popup=f'hotspot_{i}', icon=folium.Icon(color='red')).add_to(m)\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "N_RINGS_CLUSTER = 50\n",
    "DEFAULT_RESOLUTION = 14\n",
    "MAX_NUMBER_STEPS = 3000  # Assuming a maximum number of steps to take\n",
    "START_TUPLE = np.mean(boundary_pts, axis=0)\n",
    "\n",
    "# Initialize variables\n",
    "working_c = clustering_step(hotspots=hotspots, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Marker(location=[START_TUPLE[0], START_TUPLE[1]], popup=f'START', icon=folium.Icon(color='purple')).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import h3 \n",
    "\n",
    "DEFAULT_RESOLUTION = 14\n",
    "START_TUPLE = np.mean(boundary_pts, axis=0)\n",
    "\n",
    "victim_hexagons = [h3.geo_to_h3(victim[0], victim[1], DEFAULT_RESOLUTION) for victim in victims]\n",
    "print(victim_hexagons)\n",
    "\n",
    "def check_if_victim_is_detected(location: Tuple):\n",
    "    g = h3.geo_to_h3(location[0], location[1], DEFAULT_RESOLUTION)\n",
    "    if g in victim_hexagons:\n",
    "        return victim_hexagons.index(g)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusterfinder.maplib import LatLon\n",
    "from pathfinder.pathfinder import BayesianHexSearch, OutwardSpiralPathFinder, init_empty_prob_map, update_prob_map_w_hotspots, update_probability_map\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "#TODO:\n",
    "# Increase the number of victims\n",
    "# Tune all the other parameters\n",
    "# N_RING_CLUSTER has an exponential computing time\n",
    "# max_number_steps check if it makes sense logically for length of flight\n",
    "PROBABILITY_DECAY=0.95\n",
    "\n",
    "n_drones = 4  # Number of drones\n",
    "available_drones = [i for i in range(n_drones)]\n",
    "step_count = [0 for _ in range(4)]\n",
    "drone_current_pos = [START_TUPLE for _ in range(4)]\n",
    "next_round_drones = []\n",
    "\n",
    "detected_history = {}\n",
    "\n",
    "print(len(working_c))\n",
    "print(len(available_drones))\n",
    "# Main loop\n",
    "while len(working_c) > 0:\n",
    "    if len(working_c) == 0:\n",
    "        break\n",
    "    else:\n",
    "        c = working_c.pop() # [0] is location of cluster, [1] is list of hotspots\n",
    "\n",
    "    drone = available_drones.index(step_count.index(min(step_count))) # Take the drone with minimum number of steps\n",
    "\n",
    "    # Explore using drone\n",
    "    # Go to cluster center\n",
    "    path_to_cluster_centre = h3.h3_line(h3.geo_to_h3(drone_current_pos[drone][0], drone_current_pos[drone][1], DEFAULT_RESOLUTION),\n",
    "                                        h3.geo_to_h3(c[0][0], c[0][1], DEFAULT_RESOLUTION))\n",
    "    step_count[drone] += len(path_to_cluster_centre) - 1 # not inclusive of current cell\n",
    "    drone_current_pos[drone] = (c[0][0], c[0][1])\n",
    "\n",
    "    # Initialize probability map\n",
    "    target_pos = c[0]\n",
    "    target_pos_latlon = LatLon(target_pos[0], target_pos[1])\n",
    "    prob_map = init_empty_prob_map(target_pos_latlon, N_RINGS_CLUSTER)\n",
    "    prob_map = update_prob_map_w_hotspots(probability_map=prob_map, hotspots=c[1])\n",
    "    # hotspots = cluster[1]\n",
    "\n",
    "    # # Initialize pathfinder\n",
    "    pathfinder = BayesianHexSearch(DEFAULT_RESOLUTION, center=target_pos)\n",
    "\n",
    "    path = []\n",
    "    for i in range(MAX_NUMBER_STEPS):\n",
    "        # print(i)\n",
    "        drone_current_pos[drone] = pathfinder.find_next_step(drone_current_pos[drone], prob_map)\n",
    "        prob_map = update_probability_map(prob_map, drone_current_pos[drone], PROBABILITY_DECAY)\n",
    "        if i%10==0: path.append(drone_current_pos[drone])\n",
    "        step_count[drone] += 1\n",
    "\n",
    "        detected = check_if_victim_is_detected(drone_current_pos[drone])\n",
    "        if detected:\n",
    "            # Record the time step when the victim is detected\n",
    "            if detected not in detected_history.keys():\n",
    "                detected_history[detected] = step_count[drone]\n",
    "                print(f\"Drone {drone} detected a victim at step {step_count[drone]}\")\n",
    "        \n",
    "        line=folium.PolyLine(locations=path,weight=1)\n",
    "        m.add_child(line)\n",
    "    # break\n",
    "        # # Mark the drone as available again\n",
    "        # available_drones.append(drone)\n",
    "    # available_drones = next_round_drones.copy()\n",
    "\n",
    "# Print the total number of victims found and the step count for each victim detection\n",
    "# victims_found = sum([check_if_victim_is_detected(current_tuple[drone]) for drone in range(n_drones)])\n",
    "# print(f\"Total victims found: {victims_found}\")\n",
    "# print(f\"Step counts: {step_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of detected:{len(detected_history)}/{n_victims}')\n",
    "print(f'Steps{step_count}')\n",
    "print(f'Average detected time of humans:{sum(detected_history.values())/len(detected_history)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code the default policy for comparison\n",
    "\n",
    "boundary_pts = [\n",
    "    (1.34554, 103.95949),\n",
    "    (1.34552, 103.96812),\n",
    "    (1.33954, 103.96831),\n",
    "    (1.33964, 103.95952),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(victim_hexagons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_victim_is_detected_h3(h3_cell: str):\n",
    "    if h3_cell in victim_hexagons:\n",
    "        return victim_hexagons.index(h3_cell)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hexagons that cover the polygon area defined by boundary_pts\n",
    "polygon = {\n",
    "    'type': 'Polygon',\n",
    "    'coordinates': [[\n",
    "        [lng, lat] for lat, lng in boundary_pts\n",
    "    ]]\n",
    "}\n",
    "\n",
    "\n",
    "hexagons = list(h3.polyfill(polygon, DEFAULT_RESOLUTION, geo_json_conformant=True))\n",
    "\n",
    "# Convert hexagons to their lat/lng center points\n",
    "hex_centers = {h: h3.h3_to_geo(h) for h in hexagons}\n",
    "\n",
    "# Sort the hexagons by their lat/lng to create a zigzag pattern\n",
    "sorted_hexagons = sorted(hexagons, key=lambda h: (hex_centers[h][0], hex_centers[h][1]))\n",
    "\n",
    "# Create the zigzag pattern\n",
    "def create_zigzag_path(hexagons, hex_centers):\n",
    "    rows = {}\n",
    "    for hex in hexagons:\n",
    "        lat = round(hex_centers[hex][0], 6)\n",
    "        if lat not in rows:\n",
    "            rows[lat] = []\n",
    "        rows[lat].append(hex)\n",
    "    \n",
    "    zigzag_path = []\n",
    "    toggle = False\n",
    "    for lat in sorted(rows.keys()):\n",
    "        row = rows[lat]\n",
    "        if toggle:\n",
    "            zigzag_path.extend(reversed(row))\n",
    "        else:\n",
    "            zigzag_path.extend(row)\n",
    "        toggle = not toggle\n",
    "\n",
    "    return zigzag_path\n",
    "\n",
    "zigzag_path = create_zigzag_path(sorted_hexagons, hex_centers)\n",
    "\n",
    "\n",
    "zigzag_ = []\n",
    "detected_history_base = {}\n",
    "for i in range(len(zigzag_path)):\n",
    "    if i%1000==0: zigzag_.append(h3.h3_to_geo(zigzag_path[i]))\n",
    "\n",
    "    detected = check_if_victim_is_detected_h3(zigzag_path[i])\n",
    "    if detected:\n",
    "        if detected not in detected_history_base.keys():\n",
    "            detected_history_base[detected] = i\n",
    "\n",
    "line=folium.PolyLine(locations=zigzag_,weight=3)\n",
    "m.add_child(line)\n",
    "\n",
    "detected_divided = [step%(len(zigzag_path)/n_drones) for step in detected_history_base.values()]\n",
    "print(detected_history_base)\n",
    "print(detected_divided)\n",
    "\n",
    "print(f'Length:{len(zigzag_path)}')\n",
    "print(f'Average number of steps:{len(zigzag_path)/n_drones}')\n",
    "print(f'Number found{len(detected_history_base)}/{n_victims}')\n",
    "print(f'Average number of steps found {sum(detected_divided)/len(detected_divided)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
